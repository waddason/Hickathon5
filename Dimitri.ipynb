{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1j56PfuVfCKvpOclcYlgD1aT7tWnLg2lT",
      "authorship_tag": "ABX9TyOGoMVecdwEOnW6EZopDXRB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waddason/Hickathon5/blob/main/Dimitri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jqdVPDEALwSH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from os.path import exists\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib  # or import pickle\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_without_nan(df):\n",
        "    # Identifier les variables quantitatives et qualitatives\n",
        "    quantitative_vars = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    qualitative_vars = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    # Remplacer les NaN par la moyenne pour les variables quantitatives\n",
        "    df[quantitative_vars] = df[quantitative_vars].apply(lambda col: col.fillna(col.mean()), axis=0)\n",
        "\n",
        "    # Remplacer les NaN par la valeur la plus fréquente (mode) pour les variables qualitatives\n",
        "    df[qualitative_vars] = df[qualitative_vars].apply(lambda col: col.fillna(col.mode()[0] if not col.mode().empty else 'Unknown'), axis=0)\n",
        "\n",
        "    # Vérifier si des NaN restent dans le jeu de données\n",
        "    remaining_nans = df.isna().sum().sum()\n",
        "    print(f\"Nombre total de NaN restants dans df : {remaining_nans}\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "BBdaYSoW-B19"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_data(df):\n",
        "    def fix_dates(df):\n",
        "        df['piezo_measurement_date'] = df['piezo_measurement_date'].str.replace(r'CEST', '', regex=True).str.strip()\n",
        "        df['piezo_measurement_date'] = pd.to_datetime(df['piezo_measurement_date'], errors='coerce')\n",
        "        return df\n",
        "    def fix_prelev(df):\n",
        "        prelev_usage_labels = [\n",
        "                    'EAU POTABLE',\n",
        "                    'EAU TURBINEE (barrage)',\n",
        "                    'CANAUX',\n",
        "                    'INDUSTRIE et ACTIVITES ECONOMIQUES (hors irrigation, hors énergie)',\n",
        "                    'IRRIGATION',\n",
        "                    'ENERGIE',\n",
        "                       ]\n",
        "        df['prelev_TOTAL'] = df['prelev_volume_0'] + df['prelev_volume_1'] + df['prelev_volume_2'] + df['prelev_other_volume_sum']\n",
        "        for usage in prelev_usage_labels:\n",
        "            df[f'prelev_{usage}'] = (\n",
        "                (df['prelev_volume_0'] * (df['prelev_usage_label_0'] == usage).astype(int)) +\n",
        "                (df['prelev_volume_1'] * (df['prelev_usage_label_1'] == usage).astype(int)) +\n",
        "                (df['prelev_volume_2'] * (df['prelev_usage_label_2'] == usage).astype(int))\n",
        "            )\n",
        "        df = df.drop(columns=['prelev_usage_label_0', 'prelev_usage_label_1', 'prelev_usage_label_2',\n",
        "                                            'prelev_volume_0', 'prelev_volume_1', 'prelev_volume_2'])\n",
        "        return df\n",
        "    df = df.set_index('row_index')\n",
        "    df = fix_dates(df)\n",
        "    df = fix_prelev(df)\n",
        "    df = df.loc[df['piezo_qualification'] == 'Correcte']\n",
        "    df = df.drop(columns=['piezo_qualification'])\n",
        "    df = df.loc[df['piezo_status'] == 'Donnée contrôlée niveau 2']\n",
        "    df = df.drop(columns=['piezo_status'])\n",
        "    df = df.loc[df['hydro_qualification_code'] == 20]\n",
        "    df = df.drop(columns=['hydro_qualification_code'])\n",
        "    df = df.reset_index(drop=True)\n",
        "    y = df['piezo_groundwater_level_category']\n",
        "    y = y.map({'Very Low' :-2, 'Low':-1, 'Average':0, 'High':1, 'Very High':2})\n",
        "    x = df.drop(columns=['piezo_groundwater_level_category'])\n",
        "    x.rename(columns={'piezo_measurement_date': 'date', 'piezo_station_bss_id': 'id'}, inplace=True)\n",
        "    return x, y\n"
      ],
      "metadata": {
        "id": "BOIYKKPk4GbJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = ['X_train_Hi5.csv', 'X_test_Hi5.csv']\n",
        "for file_name in file_names:\n",
        "  if not exists(file_name):\n",
        "    path_r = 'drive/MyDrive/Copy\\ of\\ ' + file_name\n",
        "    path_w = './' + file_name\n",
        "    !cp $path_r $path_w"
      ],
      "metadata": {
        "id": "CY0C8jz9L-zc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = ['row_index',\n",
        " 'piezo_station_bss_id',\n",
        " 'piezo_station_altitude',\n",
        " 'piezo_station_longitude',\n",
        " 'piezo_station_latitude',\n",
        " 'piezo_measurement_date',\n",
        " 'piezo_status',\n",
        " 'piezo_qualification',\n",
        " 'meteo_rain_height',\n",
        " 'meteo_temperature_min',\n",
        " 'meteo_temperature_max',\n",
        " 'meteo_temperature_avg',\n",
        " 'meteo_temperature_avg_threshold',\n",
        " 'meteo_frost_duration',\n",
        " 'meteo_amplitude_tn_tx',\n",
        " 'meteo_temperature_avg_tntm',\n",
        " 'meteo_evapotranspiration_grid',\n",
        " 'hydro_observation_result_elab',\n",
        " 'hydro_qualification_code',\n",
        " 'distance_piezo_hydro',\n",
        " 'distance_piezo_meteo',\n",
        " 'prelev_volume_0',\n",
        " 'prelev_usage_label_0',\n",
        " 'prelev_volume_1',\n",
        " 'prelev_usage_label_1',\n",
        " 'prelev_volume_2',\n",
        " 'prelev_usage_label_2',\n",
        " 'prelev_other_volume_sum',\n",
        " 'insee_pop_commune',\n",
        " 'piezo_groundwater_level_category']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZFKONsOwN4x5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('X_train_Hi5.csv', nrows=150000, usecols=columns_to_keep)\n",
        "x, y = prep_data(df)\n"
      ],
      "metadata": {
        "id": "daT5lxX7Cj0d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "past = [10, 30, 90,]"
      ],
      "metadata": {
        "id": "f78HtDnsLv_K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "id_list = x['id'].value_counts().index.tolist()\n",
        "x_per_id = {}\n",
        "i = 0\n",
        "for id in id_list:\n",
        "    i += 1\n",
        "    if i % 250 == 1 or i == len(id_list):\n",
        "        print(f'{i}/{len(id_list)}')\n",
        "    df_idx = x.loc[x['id'] == id].copy()\n",
        "    df_idx.reset_index(drop=False, inplace=True)\n",
        "    df_idx.set_index('date', inplace=True)\n",
        "    df_idx = df_idx[~df_idx.index.duplicated()]\n",
        "    df_idx.sort_index(inplace=True)\n",
        "    df_idx = pd.concat([df_idx, df_idx.shift(periods=past, freq='D')], axis=1)\n",
        "    df_index = df_idx['index'].copy()\n",
        "    for period in past:\n",
        "        df_idx.drop(columns=[f'index_{period}'], inplace=True)\n",
        "        df_idx.drop(columns=[f'id_{period}'], inplace=True)\n",
        "    df_idx = df_idx.bfill()\n",
        "    df_idx = df_idx.drop(columns=['index'])\n",
        "    df_idx['index'] = df_index\n",
        "    df_idx = df_idx.loc[df_idx['index'].notna()]\n",
        "    x_per_id[id] = df_idx.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVV9a8C4OwgU",
        "outputId": "95f3e81a-72a9-4b43-afcd-8bde8e7e8663"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1877\n",
            "251/1877\n",
            "501/1877\n",
            "751/1877\n",
            "1001/1877\n",
            "1251/1877\n",
            "1501/1877\n",
            "1751/1877\n",
            "1877/1877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_x = pd.concat(x_per_id.values(), axis=0, ignore_index=True)\n",
        "new_x['index'] = new_x['index'].astype(int)\n",
        "new_x.set_index('index', inplace=True)\n",
        "new_x = new_x.sort_index()\n",
        "new_x = new_x.drop(columns=['id'])\n",
        "new_y = y.loc[new_x.index]"
      ],
      "metadata": {
        "id": "EeZXeFWoV8KJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(new_x, new_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "rNWkuV64kgkb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = data_without_nan(x_train)\n",
        "x_valid = data_without_nan(x_valid)"
      ],
      "metadata": {
        "id": "AbD-4vawg_J6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba6183e-b548-46b1-9df2-326ae26ff078"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de NaN restants dans df : 0\n",
            "Nombre total de NaN restants dans df : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = RobustScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "joblib.dump(scaler, 'robust_scaler.pkl')\n",
        "x_train = pd.DataFrame(x_train_scaled, columns=x_train.columns, index=x_train.index)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_valid = pd.DataFrame(x_valid_scaled, columns=x_valid.columns, index=x_valid.index)"
      ],
      "metadata": {
        "id": "BHBUiphDkYpc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanitize column names\n",
        "x_train.columns = x_train.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
        "x_valid.columns = x_valid.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n"
      ],
      "metadata": {
        "id": "gFJt9wA5I1wk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cudf  # GPU-accelerated DataFrame library\n",
        "import xgboost as xgb\n",
        "\n",
        "# Convert pandas DataFrame to cuDF DataFrame\n",
        "gpu_x_train = cudf.from_pandas(x_train)\n",
        "gpu_x_valid = cudf.from_pandas(x_valid)"
      ],
      "metadata": {
        "id": "z1Erph4RMH8c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = XGBRegressor(tree_method='hist', device='cuda', objective='reg:squarederror')\n",
        "param_grid = {\n",
        "    'n_estimators': [400, 500, 1000],\n",
        "    'learning_rate': [0.3, 0.4, 0.9],\n",
        "    'max_depth': [6, 7, 12],\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=5)\n",
        "grid_search.fit(gpu_x_train, y_train)\n",
        "train_score = grid_search.score(gpu_x_train, y_train)\n",
        "valid_score = grid_search.score(gpu_x_valid, y_valid)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Training Score:\", train_score)\n",
        "print(\"Validation Score:\", valid_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2sV62KmG5xy",
        "outputId": "5737649c-fa17-4ed7-d274-839381182709"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.3, 'max_depth': 12, 'n_estimators': 1000}\n",
            "Training Score: -0.009126919314402737\n",
            "Validation Score: -0.22804921708231726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_valid = grid_search.predict(gpu_x_valid)\n",
        "pred_valid = pd.Series(pred_valid, index=y_valid.index)\n",
        "pred_valid = pred_valid.apply(lambda x: round(x))\n",
        "accuracy = accuracy_score(y_valid, pred_valid)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "brjAvwP47_fr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a497e9c2-6b49-4f60-bbf8-8dadb32d8ae6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8659206910090302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CtpGY97IVRwh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}